{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-4e3145e75d55>, line 54)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-4e3145e75d55>\"\u001b[1;36m, line \u001b[1;32m54\u001b[0m\n\u001b[1;33m    fro lag,lag_col in zip(lags,lag_cols):\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from datetime import datetime,timedelta\n",
    "import gc\n",
    "import numpy as np,pandas as pd\n",
    "import lightgbm as lgb\n",
    "CAL_DTYPES={\"event_name_1\":\"category\",\"event_name_2\":\"category\",\"event_type_1\":\"category\",\"event_type_2\":\"category\",\"weekday\":\"category\",\"wm_yr_wk\":'int16','wday':\"int16\",'month':\"int16\",\n",
    "           \"year\":\"int16\",\"snap_CA\":\"float32\",'snap_TX':'float32','snap_WI':'float32'}\n",
    "PRICE_DTYPES={\"store_id\":\"category\",\"item_id\":\"category\",\"wm_yr_wk\":\"int16\",\"sell_price\":\"float32\"}\n",
    "pd.options.display.max_columns=50\n",
    "h=28\n",
    "max_lags=70\n",
    "tr_last=1913\n",
    "fday\n",
    "\n",
    "def create_dt(is_train=True,nrows=None,first_day=1200):\n",
    "    prices=pd.read_csv(\"../input/m5-forecasting-accuracy/sell_pices.csv\",dtype=PRICE_DTYPES)\n",
    "    for col,col_dtype in PRICES_DTYPES.items():\n",
    "        if col_dtype==\"category\":\n",
    "            prices[col]=prices[col].cat.codes.astype(\"int16\")\n",
    "            prices[col]-=prices[col].min()\n",
    "    cal=pd.read_csv(\"../input/m5-forecasting-accuracy/calendar.csv\",dtype=CAL_DTYPES)\n",
    "    cal[\"date\"]=pd.to_datetime(cal[\"date\"])\n",
    "    for col,col_dtype in CAL_DTYPES.items():\n",
    "        if col_dtype==\"category\":\n",
    "            cal[col]=cal[col].cat.codes.astype(\"int16\")\n",
    "            cal[col]-=cal[col].min()\n",
    "    start_day=max(1 if is_train else tr_last-max_lags,first_day)\n",
    "    numcols=[f\"d_{day}\" for day in range(start_day,tr_last+1)]\n",
    "    cat_cols=['id','item_id','dept_id','store_id','cat_id','state_id']\n",
    "    dtype={numcol:\"float32\" for numcol in numcols}\n",
    "    dtype.update({col:\"category\" for col in catcols if col !=\"id\"})\n",
    "    dt=pd.read_csv(\"../input/m5-forcasting-accuracy/sales_train_validation.csv\",nrows=nrows,usecols=catcols+numcols,dtype=dtype)\n",
    "    for col in catcols:\n",
    "        if col !=\"id\":\n",
    "            dt[col]=dt[col].cat.codes.astype(\"int16\")\n",
    "            dt[col]-=dt[col].min()\n",
    "    if not is_train:\n",
    "        for day in range(tr_last+1,tr_last+28+1):\n",
    "            dt[f\"d_{day}\"]=np.nan\n",
    "    dt=pd.melt(dt,\n",
    "              id_vars=catcols,\n",
    "              value_vars=[col for col in dt.columns if col.startswith(\"d_\")],\n",
    "              var_name=\"d\",\n",
    "              value_name=\"sales\")\n",
    "    dt=dt.merge(cal,on=\"d\",copy=False)\n",
    "    dt=dt.merge(prices,on=[\"store_id\",\"item_id\",\"wm_yr_wk\"],copy=False)\n",
    "    return dt\n",
    "def create_fea(dt):\n",
    "    lags=[7,28]\n",
    "    lag_cols=[f\"lag_{lag}\" for lag in lags]\n",
    "    for lag,lag_col in zip(lags,lag_cols):\n",
    "        dt[lag_col]=dt[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(lag)\n",
    "    wins=[7,28]\n",
    "    for win in wins:\n",
    "        fro lag,lag_col in zip(lags,lag_cols):\n",
    "            dt[f\"rmean_{lag}_{win}\"]=dt[[\"id\",lag_col]].groupby(\"id\")[lag_col].transform(lambda x:x.rolling(win).mean())\n",
    "    date_features={\n",
    "        \"wday\":\"weekday\",\n",
    "        \"week\":\"weekofyear\",\n",
    "        \"month\":\"month\",\n",
    "        \"quarter\":\"quarter\",\n",
    "        \"year\":\"year\",\n",
    "        \"mday\":\"day\"\n",
    "    }\n",
    "    for date_feat_name,date_feat_func in date_features.items():\n",
    "        if date_feat_name in dt.columns:\n",
    "            dt[date_feat_name]=dt[date_feat_name].astype(\"int16\")\n",
    "        else:\n",
    "            dt[date_feat_name]=getattr(dt[\"date\"].dt,date_feat_func).astype(\"int16\")\n",
    "    FIRST_DAY=800\n",
    "df=create_dt(is_train=True,first_day=FIRST_DAY)\n",
    "df.shape\n",
    "df.head()\n",
    "df.info()\n",
    "create_fea(df)\n",
    "df.shape\n",
    "df.info()\n",
    "df.head()\n",
    "df.dropna(inplace=True)\n",
    "df.shape\n",
    "cat_feats=['item_id','dept_id','store_id','cat_id','state_id']+[\"event_name_1\",\"event_name_2\",\"event_type_1\",\"event_type_2\"]\n",
    "useless_cols=[\"id\",\"date\",\"sales\",\"d\",\"wm_yr_wk\",\"weekday\"]\n",
    "train_cols=df.columns[~df.columns.isin(useless_cols)]\n",
    "X_train=df[train_cols]\n",
    "y_train=df[\"sales\"]\n",
    "train_data=lgb.Dataset(X_train,label=y_train,categorical_feature=ca_feats,free_raw_data=False)\n",
    "fake_valid_inds=np.random_choice(len(X_train),1000000)\n",
    "fake_valid_data=lgb.Dataset(X_train.iloc[fake_calid_inds],label=y_train.iloc[fake_valid_inds],categorical_feature=cat_feats,free_raw_data=False)\n",
    "params={\n",
    "    \"objective\":\"poisson\",\n",
    "    \"metic\":\"rmse\",\n",
    "    \"force_row_wise\":\"True\",\n",
    "    \"leaning_rate\":0.075,\n",
    "    \"sub_row\":0.75,\n",
    "    \"bagging_freq\":1,\n",
    "    \"lambda_12\":0.1,\n",
    "    \"metric\":[\"rmse\"],\n",
    "    'verbosity':1,\n",
    "    'num_iterations':2500,\n",
    "}\n",
    "\n",
    "m_lgb=lgb.train(params,train_data,valid_sets=[fake_valid_data],verbose_eval=100)\n",
    "m_lgb.save_model(\"model.lgb\")\n",
    "\n",
    "alphas=[1.035,1.03,1.025,1.02]\n",
    "weights=[1/len(alphas)]*len(alphas)\n",
    "sub=0.\n",
    "\n",
    "for icount,(alpha,weight) in enumerate(zip(alphas,weights)):\n",
    "    te=create_dt(False)\n",
    "    cols=[f\"F{i}\" for i in range(1,29)]\n",
    "    fro tdelta in range(0,28):\n",
    "        day=fday+timedelta(days=tdelta)\n",
    "        print(icount,day)\n",
    "        tst=te[(te.date >=day-timedelta(days=max_lags))&(te.date <=day)].copy()\n",
    "        create_fea(tst)\n",
    "        tst=tst.loc[tst.date==day,train_cols]\n",
    "        te.loc[te.date==day,\"sales\"]=alpha*m_lgb.predict(tst)\n",
    "        te_sub=te.loc[te.date>=fday,[\"id\",\"sales\"]].copy()\n",
    "        te_sub[\"F\"]=[f\"F{rank}\" for rank in te_sub.groupby(\"id\")[\"id\"].cumcount()+1]\n",
    "        te_sub=te_sub.set_index([\"id\",\"F\"]).unstack()[\"sales\"][cols].reset_index()\n",
    "        te_sub.fillna(0,inplace=True)\n",
    "        te_sub.fillna(0,inplace=True)\n",
    "        te_sub.sort_values(\"id\",inplace=True)\n",
    "        te_sub.reset_index(drop=True,inplace=True)\n",
    "        if icount==0:\n",
    "            sub=te_sub\n",
    "            sub[cols]*=weight\n",
    "        else:\n",
    "            sub[cols]+=te_sub[cols]*weight\n",
    "        print(icount,alpha,weight)\n",
    "\n",
    "sub2=sub.copy()\n",
    "sub2[\"id\"]=sub2[\"id\"].str.replace(\"validation$\",\"evaluation\")\\\n",
    "sub=pd.concat([sub,sub2],axis=0,sort=False)\n",
    "sub.to_csv(\"submission.csv\",index=False)\n",
    "sub.head(10)\n",
    "\n",
    "sub.id.nunique(),sub[\"id\"].str.contains(\"validation$\").sum()\n",
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
